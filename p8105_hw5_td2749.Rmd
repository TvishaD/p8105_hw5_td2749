---
title: "p8105_hw5_td2749"
author: "Tvisha R. Devavarapu"
date: "2022-11-03"
output: github_document
---

```{r set-up, message = FALSE}
library(tidyverse)
library(ggplot2)

knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%"
)
```

# Problem 1: Files

```{r using list.files to set up df}
full_df = 
  tibble(
    files = list.files("data/zip_data/"),
    path = str_c("data/zip_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```

```{r tidying data}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

```{r plotting}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```


# Problem 2: Homicide Data

```{r homicide_data set up}
homicide_data = 
  read_csv("./data/homicide-data.csv") %>%
  janitor::clean_names() %>% 
    unite(city_state, c(city, state), sep = ",", remove = FALSE) %>% 
    group_by(city_state, disposition) %>% 
      summarize(cases = n()) %>%
      pivot_wider(names_from = disposition, values_from = cases) %>% 
      janitor::clean_names() %>% 
      replace(is.na(.), 0) %>% 
      mutate(total_cases = closed_by_arrest + closed_without_arrest + open_no_arrest) %>% 
      mutate(unsolved_cases = closed_without_arrest + open_no_arrest) %>% 
      select(city_state, unsolved_cases, total_cases)

head(homicide_data)
```

**Raw Data Description**: The raw data consists of `r nrow(homicide_data)` rows of observations and `r ncol(homicide_data)` columns of variables. Each row identifies a distinct homicide victim's information. The variables are `r colnames(homicide_data)`. From these pieces of information, we get a picture of each victim's personal details, date of the homicide, location, and the disposition of the case. There are some missing values (NA) in the latitude and longitude columns. Most columns contain character values. Several cells in the `race`, `age`, and `sex` columns contain 'Unknown', reflecting the missing information regarding the specific individuals. There are some cities (Boston, Los Angeles, Louisville, Oakland, and Pittsburgh) where there are no cases labelled as "closed without arrest". 

```{r Baltimore prop.test}
balt_x = homicide_data %>% filter(city_state == "Baltimore,MD") %>% pull(unsolved_cases)
balt_n = homicide_data %>% filter(city_state == "Baltimore,MD") %>% pull(total_cases)

baltimore_proptest = 
  prop.test(balt_x, balt_n) %>% 
  broom::tidy()

# balt_unsolved_prop
baltimore_proptest %>% pull(estimate)

# balt_lower_bound
baltimore_proptest %>% pull(conf.low)

# balt_upper_bound
baltimore_proptest %>% pull(conf.high)
```

```{r tidy pipeline for all props}
homicide_prop_results =
  homicide_data %>% 
    mutate(
      result = purrr::map2_df(.x = unsolved_cases, .y = total_cases, ~broom::tidy(prop.test(x = .x, n = .y)))
      ) %>%
    unnest(result) %>% 
    select(city_state, unsolved_cases, total_cases, estimate, conf.low, conf.high) %>% 
    rename(unsolved_prop = estimate) %>% 
    mutate(conf_int = paste("(", round(conf.low, 3), ",", round(conf.high, 3), ")")) %>% 
    select(city_state, unsolved_cases, total_cases, unsolved_prop, conf_int, conf.low, conf.high)

```

**NOTE**: The warning message reveals that chi-square approximation may be incorrect for "city_state = Tulsa,AL". This is because this group only contains 1 homicide case (total) and 0 unsolved cases. As there is no scenario of an unsolved cases proportion (0/1) here and as the total number of cases is only 1, it is not appropriate to perform a one-sample proportion test under these circumstances. Due to this reason, this observation is *excluded* from the plot below. 

```{r plot - estimate with ci}
unsolved_prop_plot = 
  homicide_prop_results %>%
  filter(city_state != "Tulsa,AL") %>% 
    ggplot(aes(x = reorder(city_state, unsolved_prop), y = unsolved_prop)) +
      geom_point() +
      geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
      labs(title = "Proportion of Unsolved Homicides by City (2007-2017)",
           x = "Location (City and State)",
           y = "Proportion of Unsolved Homicide Cases",
           caption = "Proportions of unsolved homicides with associated 95% confidence intervals between 2007 and 2017 in major US cities.") +
      theme(plot.title = element_text(hjust = 0.5, face = "bold"),
            plot.caption = element_text(hjust = 0.5),
            axis.title = element_text(face = "bold"),
            axis.text.x = element_text(angle = 70, hjust = 1))

unsolved_prop_plot
```

# Problem 3: Simulation

```{r set seed}
set.seed(1)
```

```{r working on mean 0}
output_0_mu = vector("list", 5000)

for (i in 1:5000) {
  output_0_mu[[i]] = broom::tidy(t.test(rnorm(n = 30, mean = 0, sd = 5), mu = 0, conf.level = 0.95))
}

output_0_mu_df = 
  bind_rows(output_0_mu) %>% 
  select(estimate, p.value) %>% 
  rename(obs_mu = estimate, p_value = p.value)

head(output_0_mu_df)

```

```{r create norm_and_t_test function}
norm_and_t_test = function(mu) {
  
  if (!is.numeric(mu)) {
    stop("The mean (mu value) should be numeric")}
  
  sim_data = tibble(
    x = rnorm(n = 30, mean = mu, sd = 5),
  )
  
  sim_data %>%
    summarize(broom::tidy(t.test(x, mu = 0, conf.level = 0.95, alternative = "two.sided"))) %>% 
    select(estimate, p.value) %>% 
    rename(obs_mu = estimate, p_value = p.value)
    
}
```

```{r generating the large df with multiple means}
sim_results_df = 
  expand_grid(
    mu = c(0, 1, 2, 3, 4, 5, 6),
    iteration = 1:5000) %>% 
  mutate(results = map(mu, norm_and_t_test)) %>% 
  unnest(results)
```

```{r plot - proportion of rejections vs mu}
sim_results_df %>% 
  mutate(indicator = case_when(p_value < 0.05 ~ "reject",
                               p_value >= 0.05 ~ "fail_to_reject")) %>% 
  group_by(mu, indicator) %>%
  summarize(counts = n()) %>% 
  pivot_wider(names_from = indicator, values_from = counts) %>% 
  replace(is.na(.), 0) %>%
  mutate(total = fail_to_reject + reject,
         reject_prop = reject/total) %>% 
    ggplot(aes(x = as.factor(mu), y = reject_prop)) + 
      geom_point() +
      labs(title = "Power vs. True Mean",
           x = "True Mean",
           y = "Power") +
      theme(plot.title = element_text(hjust = 0.5, face = "bold"),
            plot.caption = element_text(hjust = 0.5),
            axis.title = element_text(face = "bold"))
```
**Association between effect size and power**: As the effect size increases, the power also increases. i.e there is a directly proportional relationship between effect size and power. Given the set sample size of 30 with 5000 trials, it is clear that the greater the effect size, the higher the power. ___

```{r plot - avg obs mu overall and rejected cases vs mu}
sim_results_df %>% 
  group_by(mu) %>% 
  mutate(overall_avg_obs_mu = sum(obs_mu)/n()) %>% 
  mutate(indicator = case_when(p_value < 0.05 ~ "reject",
                               p_value > 0.05 ~ "fail_to_reject")) %>% 
  group_by(mu, indicator, overall_avg_obs_mu) %>% 
  summarize(avg_obs_mu = sum(obs_mu)/n()) %>% 
  pivot_wider(names_from = indicator, values_from = avg_obs_mu) %>% 
  replace(is.na(.), 0) %>%
  rename(avg_obs_mu_reject = reject) %>% 
  select(-fail_to_reject) %>% 
  pivot_longer(overall_avg_obs_mu:avg_obs_mu_reject, names_to = "condition", values_to = "avg_obs_mu_val") %>% 
    ggplot(aes(x = as.factor(mu), y = avg_obs_mu_val)) +
      geom_point(aes(color = condition, shape = condition)) +
      labs(title = "Overall and Rejected Mu Vs. True Mu",
           x = "True Mu",
           y = "Observed Mu") +
      theme(plot.title = element_text(hjust = 0.5, face = "bold"),
            plot.caption = element_text(hjust = 0.5),
            axis.title = element_text(face = "bold"))
  
```
**Is the sample average of the observed mu across tests for which the null is rejected approximately equal to the true value of mu? Why or why not?**: The sample average of the observed mu across tests for which the null is rejected is not approximately equal to the true value of mu for every mu. It only begins to be so as the true value of mu increases. ___





